{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1896b2-9084-4b37-9175-f2569b7b9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# Suppress PyTorch warnings\n",
    "os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "\n",
    "# Configure logging to show only warnings and errors\n",
    "logging.basicConfig(level=logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7833db7d-5473-4380-9f2a-49516b69f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d25b4e-4ff7-4a91-ac61-39ac249815b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4a4c91-0ae6-4202-be19-67b826cd75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify required libraries\n",
    "import llama_index\n",
    "import langchain\n",
    "import streamlit\n",
    "import chromadb\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76416f38-0c2f-4f48-83c2-6726ba8c02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet PDF text snippet: UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "___________________________________________\n",
      "FORM 10-K  \n",
      "___________________________________________\n",
      "(Mark One)\n",
      "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended December 31, 2023  \n",
      "OR\n",
      "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the transition period from              to             .\n",
      "Commission file number: 001-3...\n",
      "Tesla PDF text snippet: UNITED\tSTATES\n",
      "SECURITIES\tAND\tEXCHANGE\tCOMMISSION\n",
      "Washington,\tD.C.\t20549\n",
      "FORM\t\n",
      "10-K\n",
      "(Mark\tOne)\n",
      "x\n",
      "ANNUAL\tREPORT\tPURSUANT\tTO\tSECTION\t13\tOR\t15(d)\tOF\tTHE\tSECURITIES\tEXCHANGE\tACT\tOF\t1934\n",
      "For\tthe\tfiscal\tyear\tended\t\n",
      "December\t31\n",
      ",\t2023\n",
      "OR\n",
      "o\n",
      "TRANSITION\tREPORT\tPURSUANT\tTO\tSECTION\t13\tOR\t15(d)\tOF\tTHE\tSECURITIES\tEXCHANGE\tACT\tOF\t1934\n",
      "For\tthe\ttransition\tperiod\tfrom\t_________\tto\t_________\n",
      "Commission\tFile\tNumber:\t\n",
      "001-34756\n",
      "Tesla,\tInc.\n",
      "(Exact\tname\tof\tregistrant\tas\tspecified\tin\tits\tcharter)\n",
      "Delaware\n",
      "91-2197729\n",
      "(St...\n",
      "Uber PDF text snippet: UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "____________________________________________ \n",
      "FORM 10-K\n",
      "____________________________________________ \n",
      "(Mark One)\n",
      "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended December 31, 2022\n",
      "OR\n",
      "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the transition period from_____ to _____            \n",
      "Commission File Number: 001-38902...\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Define the paths to your PDFs\n",
    "pdf_paths = {\n",
    "    'Alphabet': r\"C:\\Users\\meghn\\OneDrive\\Documents\\goog-10-k-2023 (1).pdf\",\n",
    "    'Tesla': r\"C:\\Users\\meghn\\OneDrive\\Documents\\tsla-20231231-gen.pdf\",\n",
    "    'Uber': r\"C:\\Users\\meghn\\OneDrive\\Documents\\uber-10-k-2023.pdf\"\n",
    "}\n",
    "\n",
    "# Extract text from the PDFs\n",
    "pdf_texts = {company: extract_text_from_pdf(path) for company, path in pdf_paths.items()}\n",
    "\n",
    "# Print a snippet of the text for verification\n",
    "for company, text in pdf_texts.items():\n",
    "    print(f\"{company} PDF text snippet: {text[:500]}...\")  # Adjust the snippet size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5847c2bf-4447-49ce-a68c-12e3725ad0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Revenue Profit\n",
      "Alphabet    $100   $2.0\n",
      "Tesla      $4.68   None\n",
      "Uber        $1.2   None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract financial data using regex\n",
    "def extract_financial_data(text):\n",
    "    # Example regex patterns for revenue and profit (customize based on report structure)\n",
    "    revenue_pattern = r\"Revenue[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    profit_pattern = r\"Profit[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    \n",
    "    revenue = re.search(revenue_pattern, text)\n",
    "    profit = re.search(profit_pattern, text)\n",
    "    \n",
    "    # Extracted data, defaulting to None if not found\n",
    "    revenue = revenue.group(1) if revenue else None\n",
    "    profit = profit.group(1) if profit else None\n",
    "    \n",
    "    return {'Revenue': revenue, 'Profit': profit}\n",
    "\n",
    "# Apply the extraction function to each company's text\n",
    "company_data = {}\n",
    "for company, text in pdf_texts.items():\n",
    "    company_data[company] = extract_financial_data(text)\n",
    "\n",
    "# Convert the data into a DataFrame for easier comparison\n",
    "df = pd.DataFrame(company_data).T\n",
    "df.to_csv(\"financial_data_comparison.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5005533-c34f-493c-aecb-eb9e2eaa5bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Revenue Profit\n",
      "Alphabet    $100   $2.0\n",
      "Tesla     $7,500     $1\n",
      "Uber         $55   $133\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract financial data using regex\n",
    "def extract_financial_data(text):\n",
    "    # More flexible regex patterns for revenue and profit (customize as needed)\n",
    "    revenue_pattern = r\"(Revenue|Total\\s+Revenue|Net\\s+Revenue|Sales)[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    profit_pattern = r\"(Profit|Net\\s+Income|Operating\\s+Income|Gross\\s+Profit)[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    \n",
    "    revenue = re.search(revenue_pattern, text)\n",
    "    profit = re.search(profit_pattern, text)\n",
    "    \n",
    "    # Extracted data, defaulting to None if not found\n",
    "    revenue = revenue.group(2) if revenue else None\n",
    "    profit = profit.group(2) if profit else None\n",
    "    \n",
    "    return {'Revenue': revenue, 'Profit': profit}\n",
    "\n",
    "# Apply the extraction function to each company's text\n",
    "company_data = {}\n",
    "for company, text in pdf_texts.items():\n",
    "    company_data[company] = extract_financial_data(text)\n",
    "\n",
    "# Convert the data into a DataFrame for easier comparison\n",
    "df = pd.DataFrame(company_data).T\n",
    "df.to_csv(\"financial_data_comparison.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6596bad-4d92-4726-ad04-b27b95952bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Revenue  Profit\n",
      "Alphabet    100.0     2.0\n",
      "Tesla      7500.0     1.0\n",
      "Uber         55.0   133.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract financial data using regex\n",
    "def extract_financial_data(text):\n",
    "    # More flexible regex patterns for revenue and profit (customize as needed)\n",
    "    revenue_pattern = r\"(Revenue|Total\\s+Revenue|Net\\s+Revenue|Sales)[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    profit_pattern = r\"(Profit|Net\\s+Income|Operating\\s+Income|Gross\\s+Profit)[\\s\\S]*?(\\$[\\d,]+(?:\\.\\d+)?)\"\n",
    "    \n",
    "    revenue = re.search(revenue_pattern, text)\n",
    "    profit = re.search(profit_pattern, text)\n",
    "    \n",
    "    # Extracted data, defaulting to None if not found\n",
    "    revenue = revenue.group(2) if revenue else None\n",
    "    profit = profit.group(2) if profit else None\n",
    "    \n",
    "    # Clean the data by removing commas (if any) and converting to a standard format\n",
    "    if revenue:\n",
    "        revenue = revenue.replace(',', '').replace('$', '')\n",
    "    if profit:\n",
    "        profit = profit.replace(',', '').replace('$', '')\n",
    "    \n",
    "    # Convert to float for easier handling in further processing\n",
    "    if revenue:\n",
    "        revenue = float(revenue)\n",
    "    if profit:\n",
    "        profit = float(profit)\n",
    "    \n",
    "    return {'Revenue': revenue, 'Profit': profit}\n",
    "\n",
    "# Apply the extraction function to each company's text\n",
    "company_data = {}\n",
    "for company, text in pdf_texts.items():\n",
    "    company_data[company] = extract_financial_data(text)\n",
    "\n",
    "# Convert the data into a DataFrame for easier comparison\n",
    "df = pd.DataFrame(company_data).T\n",
    "df.to_csv(\"financial_data_comparison.csv\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe4d6d5-885e-41e4-b615-3e87e130c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Company\": [\"Company A\", \"Company B\", \"Company C\"],\n",
    "    \"Revenue\": [100, 150, 200],\n",
    "    \"Profit\": [20, 30, 50],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bar plot\n",
    "df.plot(x=\"Company\", kind=\"bar\", figsize=(10, 6))\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Revenue and Profit Comparison\")\n",
    "plt.ylabel(\"Amount ($)\")\n",
    "plt.xlabel(\"Company\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"revenue_profit_comparison.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ff00d5-65f1-48eb-b02c-83bcb5a356bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"financial_data_comparison.xlsx\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "948aa5d5-b3e6-4906-994c-4d2d45cf4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae3d6c7b-5c17-45f2-a67a-4ae6e7bdf8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.34674243e-03  2.40223552e-03  1.83480582e-03 -1.54992491e-02\n",
      "   7.45987371e-02  5.99153303e-02  3.19676772e-02  2.67468151e-02\n",
      "   2.59960964e-02 -2.96183098e-02  7.61197042e-03  5.58658689e-03\n",
      "   3.26719023e-02  2.53468510e-02  1.35427415e-02  5.78699000e-02\n",
      "   1.17850594e-01  6.70695975e-02 -6.91913627e-03 -4.49889638e-02\n",
      "  -5.51183429e-03  2.83483025e-02  9.90352556e-02 -5.59788868e-02\n",
      "   3.67851406e-02 -2.57713255e-03  7.66836200e-03  7.71480054e-02\n",
      "   9.56553444e-02 -8.26762524e-03  5.24235405e-02 -2.45366376e-02\n",
      "   6.39095008e-02  1.72637124e-02  7.01922327e-02  5.68613000e-02\n",
      "  -4.50920463e-02  4.26678173e-02 -2.86563262e-02  7.85986185e-02\n",
      "   3.01986728e-02 -3.73339374e-03 -9.89009906e-03  6.54189289e-02\n",
      "   9.82317105e-02 -7.66057819e-02 -5.31081669e-02 -3.27406509e-04\n",
      "   4.13534790e-03  8.49060491e-02 -6.29577413e-02 -3.20573337e-02\n",
      "  -7.04800561e-02 -3.50319147e-02 -2.32712403e-02 -4.06736806e-02\n",
      "   1.42755546e-02 -8.09421390e-02  9.88004822e-03 -3.62574644e-02\n",
      "   3.77748758e-02 -4.64594290e-02  5.37510142e-02  1.32146450e-02\n",
      "   1.40138734e-02 -2.74445303e-02 -1.98897440e-02  1.42848551e-01\n",
      "  -2.47925464e-02 -3.18149710e-03 -7.24917427e-02  1.55803077e-02\n",
      "  -5.47653772e-02  6.78192750e-02 -8.61368254e-02  1.05579384e-02\n",
      "  -6.40081540e-02 -1.40917391e-01  6.27024099e-02 -8.31320062e-02\n",
      "   1.46647179e-02 -2.42686365e-02  5.23817018e-02  4.59520742e-02\n",
      "   7.00645242e-03  2.08211094e-02  7.79044181e-02  1.77340712e-02\n",
      "  -5.12224995e-02 -1.06098838e-02  4.13188944e-03 -2.46537402e-02\n",
      "   2.81529687e-02  6.65211910e-03 -5.93940280e-02  2.05987487e-02\n",
      "  -2.78445296e-02 -4.43434976e-02  2.90866438e-02  8.27917010e-02\n",
      "   9.95282177e-03  6.67690812e-03  8.28091130e-02  2.63493857e-04\n",
      "  -9.49992463e-02 -1.13951400e-01  3.10694035e-02 -2.03308631e-02\n",
      "  -1.22339968e-02 -4.57900427e-02 -9.61027574e-04 -3.38552259e-02\n",
      "  -8.72000083e-02 -5.19399252e-03  4.64219861e-02 -1.16417840e-01\n",
      "   6.04409613e-02 -8.60900432e-02  3.11818928e-03 -5.93203725e-03\n",
      "  -6.22655638e-02  4.55832183e-02 -7.16995597e-02 -4.25602449e-03\n",
      "  -1.33308331e-02 -1.60188098e-02  6.68109581e-02 -1.11845863e-33\n",
      "   9.83547047e-03  5.06587792e-03  1.50244376e-02  1.10236183e-01\n",
      "   4.08857428e-02 -1.40668163e-02 -5.58365770e-02  3.22771892e-02\n",
      "  -8.80328938e-02  1.82437280e-03 -3.96707002e-03 -4.89949770e-02\n",
      "   3.10912561e-02  8.40576515e-02 -3.71657498e-02 -3.23160551e-02\n",
      "  -6.20743372e-02 -9.51930508e-03  2.60292124e-02  2.49491655e-03\n",
      "  -7.29696602e-02  4.15980034e-02  1.39873391e-02 -3.41003463e-02\n",
      "  -6.90056235e-02  2.41250009e-03  2.93620285e-02 -8.08679387e-02\n",
      "  -3.58390398e-02 -1.95486657e-02 -5.25196679e-02 -5.84462769e-02\n",
      "   5.72920181e-02 -2.60349531e-02  2.80658416e-02  4.03930712e-03\n",
      "   3.61808166e-02  6.59376569e-03 -2.51837168e-02 -3.33911949e-03\n",
      "   2.34778766e-02 -2.49443259e-02  1.24654889e-01 -5.49946129e-02\n",
      "  -2.12579016e-02  1.61116458e-02  6.42328942e-03 -1.73819046e-02\n",
      "   4.08670073e-03 -3.27206962e-02  1.63139528e-04  3.46229114e-02\n",
      "  -1.08463923e-02 -3.93749475e-02  9.50971469e-02 -1.08402427e-02\n",
      "  -2.82493141e-02  2.48130970e-02  5.61928451e-02  1.89000107e-02\n",
      "  -5.36934584e-02 -7.91771151e-03  4.77821082e-02  1.38732325e-02\n",
      "   4.30383645e-02  3.61801428e-03 -3.95822339e-02 -1.11992873e-01\n",
      "   5.27318195e-02  2.66967919e-02 -2.39895787e-02  1.99866202e-02\n",
      "  -9.63651389e-02 -3.77832502e-02 -1.06186256e-01  1.35026332e-02\n",
      "  -5.11459708e-02 -7.93625694e-03 -1.05659077e-02  4.94473688e-02\n",
      "  -3.58213894e-02 -1.49826676e-01  1.42695336e-02 -6.91209361e-02\n",
      "  -3.77895012e-02 -6.90801665e-02  4.50409502e-02 -1.66615143e-01\n",
      "   7.55838379e-02 -1.00945476e-02 -5.88838682e-02  1.13463607e-02\n",
      "  -8.35671946e-02 -4.67893332e-02  1.02073848e-01 -4.47803999e-35\n",
      "   2.29515247e-02  2.02605687e-02 -9.03231092e-03  5.69148473e-02\n",
      "   5.61938584e-02  8.46668705e-02  2.10885406e-02  4.11245264e-02\n",
      "  -1.33801263e-03  1.49054108e-02 -5.84867857e-02 -2.15300992e-02\n",
      "   7.55728930e-02 -7.55578354e-02 -1.32012516e-02  2.11204849e-02\n",
      "   9.30440519e-03  1.96934678e-02  5.60477469e-03  2.65013203e-02\n",
      "  -7.00650215e-02 -5.53689292e-03  1.50643671e-02  2.56827362e-02\n",
      "   1.20322905e-01  1.06687829e-01  3.17936838e-02 -7.28855655e-03\n",
      "  -2.34720819e-02 -8.55236575e-02 -2.63102613e-02 -4.62083183e-02\n",
      "   1.53831895e-02  3.26381624e-02 -8.25131238e-02 -4.78959503e-03\n",
      "   1.40359700e-01  1.51921529e-02 -3.28214243e-02 -3.67183564e-03\n",
      "   8.15530270e-02  2.44737733e-02 -6.79932684e-02 -6.06219051e-03\n",
      "  -3.60504277e-02  1.94107997e-03 -1.14992209e-01 -4.63035814e-02\n",
      "   7.76582882e-02  1.91285613e-03 -6.63784593e-02 -9.44679324e-03\n",
      "  -5.02198189e-02 -9.87394340e-03  9.18274652e-03 -8.62740427e-02\n",
      "  -3.68765555e-02  1.44498050e-03  3.08640171e-02  1.24916900e-02\n",
      "  -3.84530760e-02 -3.87277408e-03 -3.64348060e-03 -4.79012355e-02\n",
      "   5.91625795e-02 -1.26741692e-01 -2.12645717e-02  2.09906623e-02\n",
      "  -7.15680793e-02  1.01491371e-02 -1.97857013e-03 -2.35861782e-02\n",
      "   4.42360388e-03  8.49307049e-03  2.66062059e-02  9.02619213e-03\n",
      "   4.21832316e-02  5.75294830e-02 -3.73691432e-02 -7.17524812e-02\n",
      "   1.02208667e-01 -9.84367076e-03  1.06512457e-02  6.20551147e-02\n",
      "   7.82333463e-02  6.12589978e-02 -8.80173780e-03 -4.49705869e-03\n",
      "   1.04322843e-03  3.42901126e-02 -1.25804665e-02  4.55799550e-02\n",
      "  -1.04903290e-02  1.26965702e-01  6.01976551e-02 -1.61127520e-08\n",
      "  -4.31180485e-02 -1.01540368e-02  1.01238228e-02 -7.86050968e-03\n",
      "  -6.33169264e-02 -3.46146827e-03  1.33149768e-03 -9.77645442e-02\n",
      "  -3.78194563e-02 -5.11830337e-02  7.59681240e-02 -7.83849210e-02\n",
      "  -3.55951115e-02 -3.32821347e-02  4.19391599e-03  4.19164337e-02\n",
      "  -2.59904657e-02  7.41204061e-03  3.73922400e-02  3.66032533e-02\n",
      "   1.28250774e-02  1.17808886e-01  1.03884027e-03 -3.47785540e-02\n",
      "  -3.39909457e-02  6.01576939e-02 -2.83055026e-02 -2.05665082e-02\n",
      "   2.62764487e-02 -5.09047173e-02  3.15710343e-02  7.06092790e-02\n",
      "   2.36893469e-03 -7.20478222e-02  1.27352029e-02 -1.74590442e-02\n",
      "   2.30147149e-02 -7.31286556e-02 -1.01080779e-02 -3.93641442e-02\n",
      "   1.48912286e-02  3.55265215e-02 -3.99478637e-02 -8.96821395e-02\n",
      "   1.13781057e-01  2.33707801e-02  2.15534084e-02 -5.46623282e-02\n",
      "   2.05254927e-02  1.87117290e-02 -1.38910627e-02 -7.83383325e-02\n",
      "   6.28294144e-03 -7.43739307e-03 -5.96115924e-03  3.57202888e-02\n",
      "   3.20143029e-02  8.60925540e-02 -3.16577926e-02 -2.43858062e-03\n",
      "   1.00977914e-02  8.19234103e-02  2.26312596e-02 -4.83508743e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight embedding model\n",
    "embeddings = model.encode([\"Sample text for embedding\"])\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a149e03e-e732-4e3a-8fc9-c3b11c329ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for sentence 1: [ 2.34676828e-03  2.40221224e-03  1.83472282e-03 -1.54992305e-02\n",
      "  7.45986775e-02  5.99153526e-02  3.19677219e-02  2.67468262e-02\n",
      "  2.59961654e-02 -2.96183135e-02  7.61201466e-03  5.58662089e-03\n",
      "  3.26719172e-02  2.53468733e-02  1.35428030e-02  5.78698516e-02\n",
      "  1.17850564e-01  6.70695379e-02 -6.91912463e-03 -4.49890345e-02\n",
      " -5.51191019e-03  2.83483267e-02  9.90352854e-02 -5.59788235e-02\n",
      "  3.67851406e-02 -2.57694907e-03  7.66830845e-03  7.71479160e-02\n",
      "  9.56552699e-02 -8.26757215e-03  5.24235182e-02 -2.45366357e-02\n",
      "  6.39095381e-02  1.72637608e-02  7.01921433e-02  5.68612777e-02\n",
      " -4.50920835e-02  4.26679254e-02 -2.86562406e-02  7.85985515e-02\n",
      "  3.01986430e-02 -3.73340002e-03 -9.89011955e-03  6.54189661e-02\n",
      "  9.82317775e-02 -7.66057447e-02 -5.31080775e-02 -3.27340211e-04\n",
      "  4.13543219e-03  8.49060118e-02 -6.29577115e-02 -3.20572928e-02\n",
      " -7.04800189e-02 -3.50318477e-02 -2.32712962e-02 -4.06735837e-02\n",
      "  1.42755667e-02 -8.09421986e-02  9.88013111e-03 -3.62574905e-02\n",
      "  3.77748460e-02 -4.64594588e-02  5.37510477e-02  1.32145649e-02\n",
      "  1.40138483e-02 -2.74446085e-02 -1.98897775e-02  1.42848566e-01\n",
      " -2.47925520e-02 -3.18144541e-03 -7.24917278e-02  1.55803626e-02\n",
      " -5.47653139e-02  6.78193644e-02 -8.61369222e-02  1.05579961e-02\n",
      " -6.40081391e-02 -1.40917465e-01  6.27023727e-02 -8.31319243e-02\n",
      "  1.46646546e-02 -2.42686905e-02  5.23817614e-02  4.59520258e-02\n",
      "  7.00649712e-03  2.08211113e-02  7.79044628e-02  1.77340582e-02\n",
      " -5.12225293e-02 -1.06098522e-02  4.13188059e-03 -2.46537346e-02\n",
      "  2.81530544e-02  6.65205717e-03 -5.93940802e-02  2.05987711e-02\n",
      " -2.78444532e-02 -4.43435274e-02  2.90865824e-02  8.27917382e-02\n",
      "  9.95288044e-03  6.67688344e-03  8.28090534e-02  2.63550610e-04\n",
      " -9.49992687e-02 -1.13951378e-01  3.10694035e-02 -2.03310158e-02\n",
      " -1.22339455e-02 -4.57900986e-02 -9.61051963e-04 -3.38552929e-02\n",
      " -8.72000158e-02 -5.19397995e-03  4.64219563e-02 -1.16417870e-01\n",
      "  6.04409799e-02 -8.60900655e-02  3.11815413e-03 -5.93209267e-03\n",
      " -6.22656308e-02  4.55832034e-02 -7.16996267e-02 -4.25593229e-03\n",
      " -1.33308293e-02 -1.60188191e-02  6.68110102e-02 -1.11845716e-33\n",
      "  9.83540621e-03  5.06590772e-03  1.50243714e-02  1.10236146e-01\n",
      "  4.08857651e-02 -1.40668023e-02 -5.58365844e-02  3.22770886e-02\n",
      " -8.80328417e-02  1.82428549e-03 -3.96706490e-03 -4.89950143e-02\n",
      "  3.10912672e-02  8.40575695e-02 -3.71657051e-02 -3.23160701e-02\n",
      " -6.20743185e-02 -9.51932650e-03  2.60291472e-02  2.49487767e-03\n",
      " -7.29696378e-02  4.15979587e-02  1.39874397e-02 -3.41002867e-02\n",
      " -6.90056309e-02  2.41249194e-03  2.93620899e-02 -8.08680132e-02\n",
      " -3.58390138e-02 -1.95486825e-02 -5.25196195e-02 -5.84462844e-02\n",
      "  5.72919883e-02 -2.60348655e-02  2.80657653e-02  4.03927639e-03\n",
      "  3.61808129e-02  6.59375172e-03 -2.51836479e-02 -3.33906687e-03\n",
      "  2.34778468e-02 -2.49443166e-02  1.24654964e-01 -5.49946129e-02\n",
      " -2.12579127e-02  1.61116067e-02  6.42326800e-03 -1.73819121e-02\n",
      "  4.08673100e-03 -3.27207483e-02  1.63122095e-04  3.46228108e-02\n",
      " -1.08465049e-02 -3.93748656e-02  9.50971916e-02 -1.08402399e-02\n",
      " -2.82492451e-02  2.48130076e-02  5.61928414e-02  1.89000741e-02\n",
      " -5.36934249e-02 -7.91771337e-03  4.77821939e-02  1.38732493e-02\n",
      "  4.30383794e-02  3.61799495e-03 -3.95822264e-02 -1.11992829e-01\n",
      "  5.27318306e-02  2.66967658e-02 -2.39895415e-02  1.99866500e-02\n",
      " -9.63650867e-02 -3.77832167e-02 -1.06186263e-01  1.35027245e-02\n",
      " -5.11459634e-02 -7.93632586e-03 -1.05659654e-02  4.94472906e-02\n",
      " -3.58213708e-02 -1.49826750e-01  1.42695969e-02 -6.91209733e-02\n",
      " -3.77895460e-02 -6.90802038e-02  4.50408757e-02 -1.66615248e-01\n",
      "  7.55838454e-02 -1.00946110e-02 -5.88839464e-02  1.13464408e-02\n",
      " -8.35671276e-02 -4.67893109e-02  1.02073818e-01 -4.47830775e-35\n",
      "  2.29515377e-02  2.02605035e-02 -9.03238636e-03  5.69147281e-02\n",
      "  5.61938770e-02  8.46668929e-02  2.10884903e-02  4.11244147e-02\n",
      " -1.33809564e-03  1.49054350e-02 -5.84868714e-02 -2.15301123e-02\n",
      "  7.55729675e-02 -7.55577907e-02 -1.32011818e-02  2.11205333e-02\n",
      "  9.30452347e-03  1.96935255e-02  5.60479565e-03  2.65013576e-02\n",
      " -7.00649992e-02 -5.53685566e-03  1.50642674e-02  2.56827790e-02\n",
      "  1.20322861e-01  1.06687821e-01  3.17936242e-02 -7.28860125e-03\n",
      " -2.34720837e-02 -8.55236873e-02 -2.63103619e-02 -4.62082401e-02\n",
      "  1.53831858e-02  3.26381139e-02 -8.25130939e-02 -4.78953961e-03\n",
      "  1.40359670e-01  1.51921231e-02 -3.28214616e-02 -3.67184333e-03\n",
      "  8.15532357e-02  2.44737845e-02 -6.79931939e-02 -6.06224732e-03\n",
      " -3.60504426e-02  1.94114447e-03 -1.14992268e-01 -4.63035144e-02\n",
      "  7.76582360e-02  1.91291783e-03 -6.63784221e-02 -9.44683142e-03\n",
      " -5.02198450e-02 -9.87393688e-03  9.18274745e-03 -8.62740427e-02\n",
      " -3.68765220e-02  1.44502264e-03  3.08639463e-02  1.24915987e-02\n",
      " -3.84531021e-02 -3.87279713e-03 -3.64339910e-03 -4.79012094e-02\n",
      "  5.91626503e-02 -1.26741692e-01 -2.12645214e-02  2.09905934e-02\n",
      " -7.15680495e-02  1.01491427e-02 -1.97847141e-03 -2.35861465e-02\n",
      "  4.42356616e-03  8.49307515e-03  2.66062077e-02  9.02624521e-03\n",
      "  4.21831720e-02  5.75294644e-02 -3.73692662e-02 -7.17524439e-02\n",
      "  1.02208689e-01 -9.84362606e-03  1.06512634e-02  6.20551072e-02\n",
      "  7.82333910e-02  6.12589829e-02 -8.80178530e-03 -4.49705543e-03\n",
      "  1.04324508e-03  3.42901275e-02 -1.25805289e-02  4.55799364e-02\n",
      " -1.04902117e-02  1.26965627e-01  6.01976402e-02 -1.61127520e-08\n",
      " -4.31180857e-02 -1.01541271e-02  1.01236859e-02 -7.86041096e-03\n",
      " -6.33169785e-02 -3.46157327e-03  1.33145321e-03 -9.77645367e-02\n",
      " -3.78194451e-02 -5.11830002e-02  7.59680942e-02 -7.83849582e-02\n",
      " -3.55951041e-02 -3.32822166e-02  4.19389782e-03  4.19163965e-02\n",
      " -2.59904433e-02  7.41196470e-03  3.73922810e-02  3.66032086e-02\n",
      "  1.28251621e-02  1.17808916e-01  1.03871722e-03 -3.47784534e-02\n",
      " -3.39909233e-02  6.01576790e-02 -2.83055641e-02 -2.05665100e-02\n",
      "  2.62764767e-02 -5.09047583e-02  3.15710828e-02  7.06091896e-02\n",
      "  2.36892886e-03 -7.20478222e-02  1.27352234e-02 -1.74590852e-02\n",
      "  2.30147745e-02 -7.31286332e-02 -1.01080406e-02 -3.93641554e-02\n",
      "  1.48912333e-02  3.55265215e-02 -3.99480015e-02 -8.96821097e-02\n",
      "  1.13781102e-01  2.33707875e-02  2.15533879e-02 -5.46624810e-02\n",
      "  2.05255914e-02  1.87116973e-02 -1.38910599e-02 -7.83383101e-02\n",
      "  6.28305459e-03 -7.43744522e-03 -5.96112618e-03  3.57203558e-02\n",
      "  3.20143253e-02  8.60925838e-02 -3.16578262e-02 -2.43851403e-03\n",
      "  1.00977495e-02  8.19233730e-02  2.26312894e-02 -4.83509041e-02]\n",
      "Embedding for sentence 2: [ 2.62888800e-02  9.00492370e-02  1.20620262e-02  7.23233446e-03\n",
      "  9.44921933e-03  1.60260461e-02  5.00297286e-02  7.47622997e-02\n",
      "  1.06458953e-02 -1.88402238e-03  8.43844190e-02 -4.61429246e-02\n",
      " -1.47726457e-03 -2.50199214e-02  5.56962378e-02  2.33050045e-02\n",
      "  7.69116059e-02 -1.44796483e-02 -5.38477898e-02 -2.54673734e-02\n",
      " -3.43208481e-03  9.70750023e-03  1.83175635e-02  7.23589361e-02\n",
      " -1.16812522e-02  5.40688112e-02 -2.07253862e-02  7.91309625e-02\n",
      "  4.13886830e-02  2.45341603e-02 -8.21217299e-02  8.53675008e-02\n",
      "  1.94332357e-02  3.69173512e-02  5.72964028e-02 -3.10756844e-02\n",
      " -3.53270359e-02  4.79684360e-02  4.77799773e-02  2.07379330e-02\n",
      " -8.81784782e-02 -7.31220767e-02  6.47675470e-02  1.09892315e-03\n",
      " -1.71447843e-02  6.92097247e-02 -1.25143617e-01  3.70884165e-02\n",
      "  6.20410126e-03  1.48142911e-02 -1.00089118e-01 -8.33813008e-03\n",
      " -5.24087623e-02 -8.33171830e-02  4.94718459e-03  9.82960463e-02\n",
      " -4.29286323e-02 -4.95185032e-02 -1.26670823e-02 -8.76407102e-02\n",
      " -1.43742748e-02 -3.21005620e-02 -3.83275142e-03  5.13477484e-03\n",
      "  6.48110658e-02 -3.64061706e-02 -2.38745771e-02  2.37904992e-02\n",
      " -1.13238730e-01  7.79949278e-02 -3.86024714e-02  8.36456791e-02\n",
      " -1.79991068e-04  1.04962617e-01 -1.13230646e-01 -8.49935226e-03\n",
      " -1.55518539e-02 -5.18559106e-02  2.62011383e-02 -6.48451447e-02\n",
      " -5.21472394e-02 -5.13345189e-02 -2.52430607e-02  6.49625212e-02\n",
      " -1.55025236e-02 -2.48016473e-02  6.28178567e-02 -3.59852947e-02\n",
      " -1.37409559e-02 -3.27273980e-02  3.35574411e-02  4.28707749e-02\n",
      "  7.83960968e-02  5.67178056e-03 -4.86239716e-02  7.04705939e-02\n",
      " -8.06535184e-02 -1.75835507e-03  6.46748990e-02  9.21143070e-02\n",
      "  2.75779068e-02  7.45316828e-03  2.10599136e-02 -6.68420494e-02\n",
      " -7.45469183e-02 -4.06460427e-02  4.26890478e-02 -9.24122185e-02\n",
      "  8.30637068e-02 -6.49495125e-02  4.67596436e-03 -1.95460599e-02\n",
      " -4.50467467e-02  4.30981303e-03  9.04879421e-02 -9.92047712e-02\n",
      "  5.93491420e-02 -7.49391969e-03  1.14461901e-02 -1.32692959e-02\n",
      "  1.04338219e-02 -5.99635653e-02 -3.63191850e-02  2.49469876e-02\n",
      " -4.76287566e-02 -5.03106527e-02  7.54447579e-02 -2.52768516e-33\n",
      " -8.32443591e-04 -5.79560436e-02  3.43730561e-02  3.07114869e-02\n",
      "  2.03136858e-02 -5.96281327e-03 -6.03239313e-02 -5.44431880e-02\n",
      " -5.17549254e-02 -1.93971880e-02 -4.17181328e-02  6.16856925e-02\n",
      "  1.36277666e-02 -3.72233279e-02 -4.88745645e-02 -9.86700729e-02\n",
      " -6.68472052e-02  1.30780451e-02  9.01659485e-03 -5.68256760e-03\n",
      " -8.74258019e-03  7.92862754e-03  5.05703827e-03  4.23789807e-02\n",
      "  3.13630104e-02 -6.11311570e-02  1.13131022e-02 -4.89956886e-02\n",
      "  2.65942160e-02 -3.90474088e-02  2.56358944e-02 -3.84189449e-02\n",
      "  1.93534531e-02  4.18604724e-03  4.14757989e-02  2.96398178e-02\n",
      "  1.38311293e-02 -4.19734651e-03 -5.49921300e-03  2.02509072e-02\n",
      " -7.28800148e-02 -5.38286660e-03  1.00543343e-01 -5.96853420e-02\n",
      "  8.29074010e-02 -2.05874369e-02 -4.19995449e-02  2.85830013e-02\n",
      "  4.88899760e-02 -3.61399651e-02  2.89537548e-03  1.66437775e-02\n",
      " -5.00583239e-02  1.29153598e-02  8.78426656e-02  1.61988282e-04\n",
      " -4.33948152e-02  9.22525376e-02  3.16019990e-02  6.16921373e-02\n",
      "  1.29373753e-02  2.08770800e-02 -2.28646211e-02 -3.67815830e-02\n",
      "  4.70873117e-02  3.31996847e-03  2.79555563e-03 -1.12671167e-01\n",
      "  2.26445235e-02  2.43282951e-02 -4.90137609e-03 -2.76452042e-02\n",
      " -5.73190823e-02  1.97366476e-02 -3.23321074e-02  2.33516842e-03\n",
      " -3.53368036e-02  7.51618743e-02 -9.14513890e-04 -7.33249113e-02\n",
      " -2.67428346e-02 -1.02625124e-01  4.66740318e-03 -5.16372956e-02\n",
      " -1.25251934e-02  5.40634291e-03  7.30769411e-02 -1.00890264e-01\n",
      "  4.99678887e-02 -1.14840176e-02 -5.32730632e-02  3.79191861e-02\n",
      " -1.50446668e-02 -3.31411697e-02  9.60754082e-02  9.04186179e-35\n",
      " -3.40511277e-02  9.45510715e-03  7.39619657e-02  7.52818510e-02\n",
      "  3.57883498e-02  4.05508056e-02  7.28066489e-02 -7.36427233e-02\n",
      "  3.47845815e-02 -1.07502816e-02  1.03787435e-02  4.85780230e-03\n",
      "  1.06632143e-01 -9.43011716e-02  3.95696191e-03  2.04052143e-02\n",
      "  5.83470650e-02 -2.86678853e-03 -6.31908402e-02  6.37870654e-02\n",
      " -1.84962656e-02  1.12403281e-01  2.46188790e-02  1.87205765e-02\n",
      " -4.89493832e-02  3.58789228e-02  4.32301499e-02 -2.42876709e-02\n",
      " -5.70598952e-02 -1.45658970e-01  4.31243563e-03 -4.19311710e-02\n",
      "  1.51942139e-02  3.04446686e-02 -3.04972976e-02 -3.59570868e-02\n",
      "  8.02620500e-02 -8.90729502e-02 -5.32863587e-02  4.15571146e-02\n",
      "  5.25140204e-02  3.75610478e-02  2.58359797e-02 -4.60946783e-02\n",
      " -3.87839787e-02  4.60970849e-02 -7.41384551e-02 -6.14216290e-02\n",
      "  4.41890247e-02 -3.83051597e-02  2.30223313e-02 -1.01988669e-02\n",
      " -8.68919492e-02  3.33868600e-02 -3.03869788e-02 -8.68530050e-02\n",
      "  8.43749940e-03 -5.72918281e-02 -2.46495381e-02  6.57334272e-03\n",
      " -6.40659127e-03  4.88310382e-02 -3.90463434e-02  7.30999336e-02\n",
      "  1.35090239e-02 -8.48119557e-02 -2.33724248e-02  4.00170013e-02\n",
      " -5.51775238e-03  4.73190993e-02  7.55972462e-03 -5.55488132e-02\n",
      " -5.76349022e-03 -9.03808698e-02 -4.14892212e-02  2.83547305e-02\n",
      "  5.46882972e-02  4.74114530e-02 -5.90831004e-02 -6.53027697e-03\n",
      "  7.81381875e-03  3.06736175e-02  9.66299698e-03  4.78268340e-02\n",
      " -7.13093653e-02  6.89282045e-02 -6.27608830e-03 -1.63622871e-02\n",
      " -4.00065742e-02  7.68423900e-02 -5.74911833e-02 -3.95657793e-02\n",
      "  3.31087559e-02  1.26555422e-02  6.48232922e-02 -1.45859902e-08\n",
      "  2.93341167e-02 -5.73079064e-02 -3.13954204e-02  3.49888690e-02\n",
      " -2.08325293e-02  7.12596299e-03 -3.85684259e-02 -8.51423740e-02\n",
      " -7.89149925e-02  1.65614299e-02  5.29083759e-02  4.27887365e-02\n",
      " -4.18694466e-02  2.57418677e-02 -3.39234360e-02  2.55294237e-02\n",
      " -8.38416591e-02 -4.40649018e-02  4.51839529e-02  8.64652637e-03\n",
      "  4.35756482e-02  8.43927860e-02  3.98369128e-04  1.42865647e-02\n",
      " -2.16004904e-03  9.63696390e-02 -7.57936016e-02 -9.49286111e-03\n",
      " -3.74834575e-02 -5.82770444e-02  1.07257850e-01  6.16320483e-02\n",
      "  6.96814060e-03 -1.25625968e-01  1.03089914e-01 -6.06306642e-02\n",
      "  4.22533788e-02  8.03072825e-02  2.51045767e-02  1.93946455e-02\n",
      " -3.55392359e-02  1.30945463e-02 -9.36290026e-02  1.35167781e-02\n",
      "  7.91641474e-02 -7.95445517e-02  3.44017856e-02 -6.91076890e-02\n",
      "  1.71985365e-02 -3.69217619e-02  1.66036952e-02 -2.32955553e-02\n",
      "  3.77329104e-02 -2.45075021e-02 -1.92967467e-02  2.70066373e-02\n",
      "  2.63297930e-02  6.88078776e-02 -6.12834245e-02 -1.28169160e-03\n",
      "  1.46337837e-01  3.57881980e-03  2.26255059e-02 -1.01613691e-02]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample sentences to compare\n",
    "sentences = [\"Sample text for embedding\", \"Another sample text for comparison\"]\n",
    "\n",
    "# Compute embeddings for the sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    print(f\"Embedding for sentence {i+1}: {embedding}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce996cc9-5697-4ddc-b1f4-8189f6d18eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "[[1.0000001  0.47497296]\n",
      " [0.47497296 1.0000002 ]]\n",
      "Cosine similarity between the first and second sentence: 0.4749728739261627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Compute cosine similarity between embeddings\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "# If you want to compare just two sentences\n",
    "similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(f\"Cosine similarity between the first and second sentence: {similarity_score[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c201530c-d131-4157-80c2-8ca00d5eabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d7db82b-cfd6-4000-8f5c-b1e54f23d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "  - More data for analysis\n",
      "\n",
      "Cluster 1:\n",
      "  - Sample text for embedding\n",
      "  - Another example of text\n",
      "  - Different example\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Sample sentences and their embeddings\n",
    "sentences = [\"Sample text for embedding\", \"Another example of text\", \"More data for analysis\", \"Different example\"]\n",
    "embeddings = model.encode(sentences)  # Assume you have already created embeddings for the sentences\n",
    "\n",
    "# Perform KMeans clustering\n",
    "num_clusters = 2\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Group sentences by their cluster label\n",
    "clusters = {i: [] for i in range(num_clusters)}\n",
    "for sentence, label in zip(sentences, labels):\n",
    "    clusters[label].append(sentence)\n",
    "\n",
    "# Print sentences grouped by their cluster labels\n",
    "for cluster_label, cluster_sentences in clusters.items():\n",
    "    print(f\"Cluster {cluster_label}:\")\n",
    "    for sentence in cluster_sentences:\n",
    "        print(f\"  - {sentence}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf6b1a1b-9bf0-4838-b984-9cffe61f9910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Sample text for embedding\n",
      "Cluster 1: Another example of text\n",
      "Cluster 0: More data for analysis\n",
      "Cluster 1: Different example\n"
     ]
    }
   ],
   "source": [
    "sentence_labels = kmeans.labels_\n",
    "labeled_sentences = list(zip(sentences, sentence_labels))\n",
    "for sentence, label in labeled_sentences:\n",
    "    print(f\"Cluster {label}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ef14aa-e035-4883-b146-91b998a79d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Sample data\n",
    "embeddings = np.random.rand(10, 5)  # 10 samples, 5 features\n",
    "kmeans = KMeans(n_clusters=3)  # Example: clustering into 3 clusters\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=kmeans.labels_)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"pca_scatter_plot.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a946d97-a736-45ae-9dc0-029479ee4c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, kmeans.labels_, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a classifier (Logistic Regression in this case)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0888a002-e23c-4eb5-a93f-f0ca0c630dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546837e-13ea-4299-befc-52af986ef5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1740499-41d5-4138-b1b4-4422d5a1880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "390bfcac-af7c-450d-bf8b-ac4523c2bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from your training data (example)\n",
    "train_data = [{'sentence': sentence} for sentence in sentences]  # 'sentences' should be your list of sentences\n",
    "\n",
    "train_dataset = Dataset.from_dict({'sentence': sentences})  # Convert to Dataset\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8479aa7-0ae6-44c3-9c0c-7fbd8fc27574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in model training: name 'Dataset' is not defined\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset  # Correct import of the Dataset class\n",
    "\n",
    "# Sample sentences for training (you can replace this with your own data)\n",
    "sentences = [\n",
    "    'This is a sentence.',\n",
    "    'This is another sentence.',\n",
    "    'How are you doing today?',\n",
    "    'I am learning machine learning.',\n",
    "    'Sentence transformers are great for NLP tasks.'\n",
    "]\n",
    "\n",
    "# Create InputExamples from the sentences for training\n",
    "# Here we use the same sentence pair for simplicity, but you can pair them differently\n",
    "train_examples = [InputExample(texts=[sentence, sentence], label=0) for sentence in sentences]\n",
    "\n",
    "# Create a HuggingFace Dataset from the sentence examples\n",
    "data_dict = {'sentence_1': sentences, 'sentence_2': sentences}\n",
    "\n",
    "# Correctly create a Dataset from the dictionary\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "# Create a DataLoader from the dataset\n",
    "train_dataloader = DataLoader(train_examples, batch_size=2, shuffle=True)\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the cosine similarity loss\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Fine-tune the model\n",
    "try:\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=4, warmup_steps=100)\n",
    "    print(\"Model training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in model training: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eef296f-514f-4d42-a877-006f3dff0fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence_1', 'sentence_2'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Example data\n",
    "data_dict = {\n",
    "    \"sentence_1\": [\"This is a sentence.\", \"Another sentence.\"],\n",
    "    \"sentence_2\": [\"This is a sentence.\", \"A different sentence.\"]\n",
    "}\n",
    "\n",
    "# Create a Dataset from the dictionary\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "# Print the dataset to verify\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d9b178-1b9c-4fb2-a6cf-19ad04549c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuning completed and saved!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample, losses, SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Create a sample dataset with similarity scores as labels (1.0 for similar, 0.0 for dissimilar)\n",
    "dataset = [\n",
    "    {\"sentence_1\": \"Hello, how are you?\", \"sentence_2\": \"Hi, how have you been?\", \"label\": 1.0},\n",
    "    {\"sentence_1\": \"What is your name?\", \"sentence_2\": \"Could you tell me your name?\", \"label\": 1.0},\n",
    "    {\"sentence_1\": \"I enjoy reading books.\", \"sentence_2\": \"Reading is my favorite hobby.\", \"label\": 1.0},\n",
    "    {\"sentence_1\": \"It's a sunny day.\", \"sentence_2\": \"The weather is bright and sunny.\", \"label\": 1.0},\n",
    "]\n",
    "\n",
    "# Prepare the data for training\n",
    "train_examples = [\n",
    "    InputExample(texts=[row[\"sentence_1\"], row[\"sentence_2\"]], label=row[\"label\"])\n",
    "    for row in dataset\n",
    "]\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "\n",
    "# Load a pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Define a loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=4, warmup_steps=100)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('fine_tuned_sentence_transformer')\n",
    "print(\"Model fine-tuning completed and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8b0488-e723-412e-a1a2-bbfced57983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d87c434-d60e-4cb8-8935-fb70758c0eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers and Accelerate are working correctly!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "\n",
    "print(\"Transformers and Accelerate are working correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08da68af-b736-4cf9-977a-c8b331f3eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.96326468e-02 -1.79807190e-02  1.01756072e-02 -1.51771549e-02\n",
      "   5.54744001e-05 -6.93052411e-02  6.68288991e-02  6.26461133e-02\n",
      "   1.88734625e-02  4.84342650e-02 -8.44402835e-02  4.35467288e-02\n",
      "   3.02871671e-02  7.58361816e-03  3.31148952e-02 -2.44786330e-02\n",
      "  -7.93212503e-02 -5.11649549e-02  3.63172847e-03 -6.62944019e-02\n",
      "  -1.32014826e-01 -7.16472231e-03 -2.76506413e-02 -3.44766043e-02\n",
      "   6.28687441e-02  1.01452537e-01 -5.73814800e-03 -5.20127006e-02\n",
      "   1.42729154e-03 -7.09168389e-02 -1.00487813e-01  1.16416015e-01\n",
      "   6.41701743e-02  5.97182438e-02  1.41863273e-02  5.57095259e-02\n",
      "   8.12012777e-02 -6.41406551e-02  1.54892961e-03  7.68235186e-03\n",
      "  -9.65531543e-02  5.58917597e-02  4.01154608e-02 -2.50361189e-02\n",
      "  -9.02409479e-03 -5.09955026e-02 -2.76898891e-02 -5.12793213e-02\n",
      "   7.57109523e-02  2.26003360e-02  6.78671245e-03 -1.23196011e-02\n",
      "   5.08785961e-05 -3.65584940e-02 -1.36210979e-03 -1.11579942e-02\n",
      "   7.82819390e-02  1.12473201e-02 -2.08325237e-02 -3.30178775e-02\n",
      "  -5.19911349e-02  3.97258252e-02 -5.15411720e-02  8.87709707e-02\n",
      "   3.15159895e-02 -7.56186992e-03  4.87286737e-03  4.12037857e-02\n",
      "   1.67851355e-02 -4.42476906e-02 -8.93128589e-02  3.38600650e-02\n",
      "  -3.65404226e-02  8.18445385e-02  1.09854765e-01 -3.85636613e-02\n",
      "   5.65247908e-02 -9.72836372e-03  5.85040711e-02 -3.72565985e-02\n",
      "   5.53566217e-02 -4.42882963e-02 -3.83609496e-02  4.02068757e-02\n",
      "   2.20271815e-02 -7.66739175e-02  3.28819305e-02  1.21345073e-01\n",
      "   4.04883400e-02 -1.53804794e-02 -6.85009779e-03 -2.23006830e-02\n",
      "  -9.70002078e-03  3.30964923e-02 -8.04741830e-02 -1.04542794e-02\n",
      "   4.49134260e-02 -3.19669209e-02 -4.27516699e-02  8.21839273e-02\n",
      "  -5.30802794e-02 -3.18343714e-02  3.37458551e-02  1.93976238e-02\n",
      "  -2.11247988e-02  1.02958605e-02  1.65066570e-02  7.45965317e-02\n",
      "   5.77990115e-02 -6.16490468e-02 -3.17637026e-02  2.23884638e-03\n",
      "   5.97260194e-03 -2.02225558e-02  4.20454666e-02  9.12238806e-02\n",
      "   3.47850546e-02  6.67823330e-02  8.94626081e-02  5.30772284e-02\n",
      "   1.27215171e-02  8.81352872e-02 -7.40206614e-02 -2.15097307e-03\n",
      "  -4.08183262e-02 -5.37841171e-02 -9.81901772e-03 -5.97857886e-29\n",
      "  -6.54276311e-02 -2.97152642e-02  1.14453146e-02  2.30205562e-02\n",
      "   3.05663683e-02 -2.43406626e-03  6.04714267e-02  1.00580819e-01\n",
      "  -7.65209049e-02  2.10580043e-02  1.76573731e-02  6.29284009e-02\n",
      "  -2.28692796e-02  7.23517016e-02  3.88246886e-02 -5.45961410e-02\n",
      "  -1.59114208e-02  3.02813370e-02 -6.88954666e-02 -2.26847194e-02\n",
      "   1.93562210e-02 -2.89220177e-02  3.89489271e-02  7.58580565e-02\n",
      "   3.06937899e-02 -3.35347988e-02  3.95643823e-02 -5.36385924e-02\n",
      "   8.66507143e-02  1.58731788e-02 -3.43047604e-02  9.36054531e-03\n",
      "  -4.95265983e-02 -1.08600613e-02 -1.42749082e-02 -4.13622782e-02\n",
      "  -2.17520781e-02 -5.77592328e-02  5.28485514e-02  2.98009757e-02\n",
      "  -2.37987023e-02  2.23306231e-02  3.28363553e-02 -2.32322700e-02\n",
      "   1.16105497e-01  1.36918612e-02  2.83346549e-02  1.68207439e-03\n",
      "  -5.42888464e-03 -7.88391102e-03 -7.25127831e-02  4.81810346e-02\n",
      "   9.89126787e-02  3.63072567e-02 -4.27179178e-03 -9.94431786e-03\n",
      "   3.69934328e-02 -3.49826589e-02 -2.15158649e-02  4.46732230e-02\n",
      "  -5.50852083e-02  9.25517380e-02  2.52228063e-02 -4.47459593e-02\n",
      "  -3.40392552e-02  7.19049126e-02  7.23584043e-03  4.86504026e-02\n",
      "   6.86480701e-02  4.08173986e-02 -7.88309351e-02  2.03396976e-02\n",
      "  -4.84706834e-03 -1.71689317e-02 -7.17229173e-02 -1.14546204e-02\n",
      "   2.23200098e-02 -6.92762285e-02 -5.00247888e-02 -7.69159989e-03\n",
      "   1.02694016e-02 -2.89268252e-02 -1.16543891e-03 -4.90665920e-02\n",
      "   1.04153335e-01  5.14017045e-02  4.92656464e-03 -1.17762260e-01\n",
      "  -2.92799319e-03  3.77529464e-03  1.09049082e-02 -8.82120430e-02\n",
      "   1.48248188e-02  1.60510056e-02 -4.33535576e-02  2.99925885e-32\n",
      "   2.74733221e-03 -3.79131027e-02 -3.34279910e-02  9.88938939e-03\n",
      "  -6.37502819e-02 -3.30428928e-02  1.18163601e-02 -1.31444214e-02\n",
      "  -5.04866503e-02  1.16726227e-01  3.45639847e-02 -3.42459045e-02\n",
      "  -5.36253415e-02  6.75340891e-02  3.26774805e-03 -2.83607729e-02\n",
      "  -6.95849434e-02  3.30692232e-02 -6.33303449e-02 -2.42066812e-02\n",
      "  -3.47242691e-02  4.32935990e-02 -7.33078495e-02  1.81984529e-02\n",
      "   9.39886943e-02 -3.73682790e-02 -6.66713566e-02  2.17240900e-02\n",
      "   2.44922563e-02  7.32129365e-02 -7.88822118e-03  1.54825067e-02\n",
      "  -4.83058281e-02 -8.74277651e-02  6.43824786e-02 -1.98260006e-02\n",
      "  -5.91482222e-03 -3.53432223e-02 -1.24430191e-02  4.68447851e-03\n",
      "   6.14141636e-02 -4.25050035e-02  6.98525384e-02  8.67187753e-02\n",
      "  -8.12650286e-03  2.08774917e-02  6.23167632e-03  7.80066662e-03\n",
      "  -2.52034012e-02 -3.87292355e-02 -4.24916744e-02 -4.60417122e-02\n",
      "   8.49474296e-02 -1.26448736e-01  3.03809606e-02 -8.43578763e-03\n",
      "   7.25590661e-02 -2.55678711e-03 -4.62760329e-02 -4.75766622e-02\n",
      "  -8.18574503e-02  2.02193367e-03  6.99940771e-02  3.20064798e-02\n",
      "   9.84241068e-03 -6.83358908e-02  1.04347235e-02 -4.47555259e-02\n",
      "  -9.81542170e-02 -1.03187457e-01  5.21093830e-02  2.56470013e-02\n",
      "  -3.81497331e-02  9.29472223e-03 -1.19896680e-01  1.51988845e-02\n",
      "   4.51719575e-03  4.06591035e-02 -8.97695795e-02  4.41180393e-02\n",
      "   6.68991432e-02 -2.55932808e-02  3.61198485e-02  6.36168122e-02\n",
      "  -6.59546182e-02  8.64000395e-02  9.35659464e-03  3.95731069e-02\n",
      "  -6.94018602e-02 -5.55940941e-02 -1.45200035e-02  8.02446380e-02\n",
      "   9.92228836e-03 -3.06333974e-02 -1.21572902e-02 -1.64068229e-06\n",
      "  -1.69097837e-02 -5.97097091e-02  4.36757691e-02 -7.61372447e-02\n",
      "   1.78488269e-02  8.05762038e-02 -2.19107810e-02 -6.08005896e-02\n",
      "  -6.61140829e-02 -1.55664943e-02  6.74393624e-02  1.82621144e-02\n",
      "  -3.22736092e-02  4.62093242e-02  1.34428889e-01 -3.65588698e-03\n",
      "   1.01197511e-01 -3.15725468e-02  4.41418437e-04  2.19325162e-02\n",
      "   2.48480160e-02  1.81734450e-02 -3.74990725e-03  1.00999966e-01\n",
      "  -8.12116340e-02 -1.37683377e-03  8.15198645e-02  6.75966814e-02\n",
      "   9.08909589e-02 -2.18550842e-02  2.30117072e-03  7.61031359e-03\n",
      "  -3.79810594e-02  2.13970691e-02  7.29943393e-03 -7.57236630e-02\n",
      "   4.36795466e-02 -6.20630160e-02  2.11151130e-03 -4.70321998e-02\n",
      "  -2.41588596e-02  7.50810802e-02  2.56944075e-02 -6.89462274e-02\n",
      "  -5.12150452e-02 -4.55717929e-03  5.00379167e-02 -7.83896148e-02\n",
      "  -2.08202377e-03 -3.18042226e-02 -1.49687389e-02  3.89037654e-02\n",
      "   1.92321520e-02  2.09392756e-02  1.05181284e-01  1.71534140e-02\n",
      "  -1.16050102e-01 -3.50103453e-02  1.07851047e-02  6.90729544e-02\n",
      "   4.77014147e-02  6.45470396e-02  1.51201589e-02 -1.75339188e-02]\n",
      " [-3.36303301e-02  3.76134855e-03 -4.83359806e-02 -1.43589079e-02\n",
      "   1.60319004e-02 -4.11103219e-02  4.49413136e-02  9.17300116e-03\n",
      "   8.48999713e-03  6.65511563e-02 -6.98844120e-02  9.59008280e-03\n",
      "   2.26293374e-02  1.10014696e-02  1.63029935e-02 -1.45106455e-02\n",
      "  -8.24749246e-02 -1.80049054e-02  1.99487768e-02 -9.34615210e-02\n",
      "  -2.28745081e-02 -5.33249415e-02  1.31628728e-02 -4.72217724e-02\n",
      "   7.32726529e-02  1.38883144e-01  2.81084273e-02 -5.76178590e-03\n",
      "   3.41529995e-02 -4.34976406e-02 -7.91979283e-02  1.02775581e-01\n",
      "   9.80207697e-02  8.89631361e-02  6.58396482e-02  3.39474231e-02\n",
      "   6.06737584e-02 -6.22657463e-02  7.19809067e-03  2.91089006e-02\n",
      "  -7.14022890e-02  8.09341110e-03  5.86287044e-02 -5.32276882e-03\n",
      "   3.27359624e-02 -2.27060951e-02  1.36079909e-02 -2.99172588e-02\n",
      "   8.02582595e-03 -3.38936672e-02  2.98107904e-03 -7.73868412e-02\n",
      "  -5.38488366e-02 -4.87473123e-02 -1.84656456e-02 -6.31498545e-02\n",
      "   6.94986284e-02 -7.79929617e-03 -1.03313755e-02 -1.71595551e-02\n",
      "  -1.51700107e-03  5.75843602e-02 -3.54018882e-02  4.88314554e-02\n",
      "   4.64434512e-02 -4.00107633e-03  9.85425897e-03  7.74434209e-02\n",
      "  -9.30145942e-03 -5.23559749e-02 -9.76725668e-02  2.86989156e-02\n",
      "  -3.85245192e-03  1.24681480e-01  1.54271781e-01 -1.95292253e-02\n",
      "   4.15282883e-02  8.81567877e-03  5.32839596e-02 -2.45680138e-02\n",
      "   3.02330218e-02 -5.66962510e-02 -6.36959746e-02  6.60932288e-02\n",
      "   3.42839584e-02 -3.80030461e-02  7.82167092e-02  8.86048377e-02\n",
      "   4.17850306e-03 -3.84224765e-02 -5.04350737e-02 -9.04732272e-02\n",
      "   7.75680393e-02  1.80198103e-02 -8.12111124e-02  2.50442158e-02\n",
      "   1.85358077e-02  5.54641359e-04 -1.49213187e-02  3.74496393e-02\n",
      "  -6.22249804e-02 -5.08196056e-02 -1.49894422e-02 -1.36450604e-02\n",
      "  -2.34556384e-02  2.75990348e-02  4.32467125e-02  1.03329934e-01\n",
      "   2.27383412e-02 -1.81141123e-02 -4.06880453e-02  3.49165611e-02\n",
      "   1.00164106e-02 -7.81731866e-03  1.14597782e-01  1.05337054e-01\n",
      "  -4.50782478e-02  5.45785017e-02  8.66361931e-02  6.08313121e-02\n",
      "   2.40064040e-02  5.72575852e-02 -1.44117311e-01 -1.15904771e-02\n",
      "  -4.94757630e-02 -1.11425675e-01  3.88720725e-03 -5.13222113e-29\n",
      "   2.71052890e-03  3.62752192e-02 -2.23625209e-02  9.54759866e-02\n",
      "   1.28900371e-02 -9.42869391e-03  9.75506287e-03  7.40592852e-02\n",
      "  -4.73074503e-02  5.81201538e-02  1.32386163e-02  2.34939959e-02\n",
      "  -2.16720831e-02  8.68606418e-02  1.15242032e-02 -7.24704117e-02\n",
      "  -5.56237921e-02 -1.15047600e-02 -3.17863114e-02 -1.11834398e-02\n",
      "  -6.19193502e-02  2.33142357e-03  2.13744007e-02  5.68268150e-02\n",
      "  -2.73195095e-02  3.38637307e-02 -1.09025380e-02 -7.44795129e-02\n",
      "   7.24836588e-02 -3.19059449e-03 -6.94769025e-02 -1.96607299e-02\n",
      "  -7.25205466e-02 -6.25060573e-02 -2.77853012e-02 -1.60980541e-02\n",
      "   1.09261833e-02 -9.57428068e-02  1.01128761e-02  3.62895764e-02\n",
      "  -1.55219231e-02  2.77086049e-02 -3.71846259e-02 -4.90247831e-02\n",
      "   1.12306304e-01  2.61131618e-02  3.03119477e-02 -3.29287499e-02\n",
      "  -3.67242210e-02  4.89197373e-02 -6.46855624e-04  2.14930195e-02\n",
      "   6.95297942e-02  2.36080810e-02 -6.00849511e-03 -1.29582807e-02\n",
      "   5.36447912e-02 -5.82913607e-02  5.93300983e-02  7.87837878e-02\n",
      "  -4.48070429e-02 -7.65443081e-03  3.93237993e-02  1.25734890e-02\n",
      "   7.94989232e-04  7.48374537e-02  3.74205373e-02  1.97750404e-02\n",
      "   9.10485685e-02 -4.93593048e-03 -1.10935248e-01 -7.71250529e-03\n",
      "   2.65455451e-02 -6.28683418e-02 -8.80880430e-02  2.21109316e-02\n",
      "   1.25429891e-02 -6.75265566e-02 -3.99105251e-02  3.95979695e-02\n",
      "  -2.14743218e-03  5.60481250e-02 -2.23048008e-03 -2.46468522e-02\n",
      "   9.27414447e-02  4.65264395e-02  9.97059699e-03 -1.44758269e-01\n",
      "  -5.51403053e-02  5.55034615e-02 -6.36174949e-03 -7.90851265e-02\n",
      "   1.39811570e-02 -3.06099858e-02  3.13709900e-02  2.98817923e-32\n",
      "  -4.63319616e-03  3.09013817e-02 -4.45171781e-02  2.98668928e-02\n",
      "  -2.34119454e-03 -5.96208684e-02  3.43873128e-02 -1.28047308e-02\n",
      "  -4.61527938e-03  1.08297527e-01 -3.01558618e-02 -4.87271585e-02\n",
      "  -6.69727549e-02  6.09347038e-02  3.97223122e-02 -1.75016019e-02\n",
      "  -4.76873890e-02 -6.06469903e-03 -3.21791843e-02  1.01233041e-03\n",
      "   7.36253476e-03  9.51084346e-02 -1.73432194e-02 -5.07975481e-02\n",
      "   2.42134202e-02  3.05635785e-03 -7.44883791e-02  4.75226715e-03\n",
      "   3.58068831e-02  2.31676158e-02  5.16893789e-02  4.93020145e-03\n",
      "  -6.74214661e-02 -9.60978866e-02 -1.05022965e-02 -2.32573655e-02\n",
      "   4.29990031e-02  3.58786210e-02 -2.04635947e-03 -2.04315339e-03\n",
      "   1.49874622e-02 -1.97760817e-02  3.10085118e-02  3.09775714e-02\n",
      "  -4.04878631e-02  3.57648777e-03  4.29592915e-02 -1.59362108e-02\n",
      "   1.45045703e-03  1.88309737e-02 -5.45415990e-02 -1.98323652e-02\n",
      "   4.46965508e-02 -1.00167975e-01  5.18023930e-02  1.35991964e-02\n",
      "   1.49162384e-02 -5.00837639e-02  4.46173996e-02 -2.00384725e-02\n",
      "  -3.82402316e-02 -1.81792155e-02  2.59825308e-02  2.64602639e-02\n",
      "   1.54189076e-02 -6.42006025e-02 -2.35434845e-02 -1.81160262e-03\n",
      "  -8.11524466e-02 -6.77869990e-02  4.86554988e-02  5.45542277e-02\n",
      "  -4.59885225e-02  4.20620963e-02 -9.63164717e-02 -6.47989884e-02\n",
      "   3.37444283e-02  5.17104380e-02 -3.18608619e-02  4.52333912e-02\n",
      "   7.60540972e-03 -5.57254963e-02 -4.12714817e-02  3.70905288e-02\n",
      "  -2.95582693e-02  1.02698207e-01  2.60904580e-02  7.90881086e-03\n",
      "  -1.75812915e-02 -8.67465958e-02 -8.77914056e-02  1.29233181e-01\n",
      "   2.29795408e-02 -1.66849326e-02  1.81511405e-05 -1.69722932e-06\n",
      "  -2.85276994e-02 -5.54407528e-03 -4.45571318e-02 -6.52080327e-02\n",
      "   4.68512774e-02  2.19347049e-02 -1.91215239e-02 -4.22419831e-02\n",
      "  -3.49344723e-02  7.48129794e-03  1.42277688e-01 -2.59774458e-02\n",
      "  -2.68138312e-02  7.58155882e-02  1.16377942e-01 -2.20462997e-02\n",
      "   9.21130702e-02 -2.62564663e-02 -7.95625616e-03  4.07290570e-02\n",
      "   1.08808503e-02  1.58924423e-02 -3.34215872e-02  2.37562880e-02\n",
      "  -8.00597966e-02 -2.61720866e-02  7.71789551e-02  7.72172883e-02\n",
      "   5.10052964e-02  5.86173721e-02 -5.99347474e-03  2.66647022e-02\n",
      "   2.86762118e-02 -4.42966120e-03 -1.76714156e-02 -1.13260381e-01\n",
      "   3.31925824e-02 -3.34053971e-02 -9.58590303e-03 -7.41271153e-02\n",
      "   7.94137735e-03  2.74689347e-02 -3.63975670e-03 -2.48762835e-02\n",
      "  -5.64831719e-02 -2.61733751e-03  1.07796058e-01 -4.44694385e-02\n",
      "  -2.22082846e-02  1.80067830e-02 -3.27489376e-02  1.87318015e-03\n",
      "   6.39801100e-03  4.91347015e-02  9.81390104e-02 -1.03608491e-02\n",
      "  -6.46568686e-02 -1.81182893e-03 -7.20895547e-03  9.17224139e-02\n",
      "   4.25735041e-02  8.24145526e-02 -4.14579846e-02 -1.42913936e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "fine_tuned_model = SentenceTransformer('fine_tuned_sentence_transformer')\n",
    "\n",
    "# Example usage: Compute embeddings for sentences\n",
    "sentences = [\"I love programming.\", \"Coding is my passion.\"]\n",
    "sentence_embeddings = fine_tuned_model.encode(sentences)\n",
    "\n",
    "# Output the embeddings\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbf37a5-0731-4b43-8b4f-f9b5a378be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the embeddings to a file\n",
    "with open(\"sentence_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sentence_embeddings, f)\n",
    "\n",
    "print(\"Embeddings saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51b1aa0-dd7f-4f5f-9965-2cecf95eb710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentence: Could you tell me your name?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Query sentence\n",
    "query = \"I enjoy coding.\"\n",
    "\n",
    "# Encode the query using the fine-tuned model\n",
    "query_embedding = fine_tuned_model.encode([query])\n",
    "\n",
    "# Calculate cosine similarity between the query and stored embeddings\n",
    "similarities = cosine_similarity(query_embedding, sentence_embeddings)\n",
    "\n",
    "# Get the index of the most similar sentence\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "# Print the most similar sentence\n",
    "print(f\"Most similar sentence: {dataset[most_similar_index]['sentence_2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f7f9b36-0d8c-4b3b-8e16-8485978cbebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 22:45:56.761 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run E:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"Sentence Similarity Search\")\n",
    "\n",
    "query = st.text_input(\"Enter a sentence:\")\n",
    "\n",
    "if query:\n",
    "    query_embedding = fine_tuned_model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, sentence_embeddings)\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    \n",
    "    st.write(f\"Most similar sentence: {dataset[most_similar_index]['sentence_2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425a639c-04cc-4d5a-8c7d-063263f95eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Set n_jobs to 1 to avoid multithreading issues\n",
    "# kmeans = KMeans(n_jobs=1)  # Ensure that the KMeans uses a single thread for processing\n",
    "\n",
    "# # Perform clustering and assign the labels\n",
    "# labels = kmeans.fit_predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6d92b-bb52-431a-8054-7fdbbe4e368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
